// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/speech/v1beta1/cloud_speech.proto
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Cloud.Speech.V1Beta1 {

  /// <summary>Holder for reflection information generated from google/cloud/speech/v1beta1/cloud_speech.proto</summary>
  public static partial class CloudSpeechReflection {

    #region Descriptor
    /// <summary>File descriptor for google/cloud/speech/v1beta1/cloud_speech.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static CloudSpeechReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "Ci5nb29nbGUvY2xvdWQvc3BlZWNoL3YxYmV0YTEvY2xvdWRfc3BlZWNoLnBy",
            "b3RvEhtnb29nbGUuY2xvdWQuc3BlZWNoLnYxYmV0YTEaHGdvb2dsZS9hcGkv",
            "YW5ub3RhdGlvbnMucHJvdG8aI2dvb2dsZS9sb25ncnVubmluZy9vcGVyYXRp",
            "b25zLnByb3RvGhdnb29nbGUvcnBjL3N0YXR1cy5wcm90byKUAQoUU3luY1Jl",
            "Y29nbml6ZVJlcXVlc3QSPgoGY29uZmlnGAEgASgLMi4uZ29vZ2xlLmNsb3Vk",
            "LnNwZWVjaC52MWJldGExLlJlY29nbml0aW9uQ29uZmlnEjwKBWF1ZGlvGAIg",
            "ASgLMi0uZ29vZ2xlLmNsb3VkLnNwZWVjaC52MWJldGExLlJlY29nbml0aW9u",
            "QXVkaW8ilQEKFUFzeW5jUmVjb2duaXplUmVxdWVzdBI+CgZjb25maWcYASAB",
            "KAsyLi5nb29nbGUuY2xvdWQuc3BlZWNoLnYxYmV0YTEuUmVjb2duaXRpb25D",
            "b25maWcSPAoFYXVkaW8YAiABKAsyLS5nb29nbGUuY2xvdWQuc3BlZWNoLnYx",
            "YmV0YTEuUmVjb2duaXRpb25BdWRpbyKeAQoZU3RyZWFtaW5nUmVjb2duaXpl",
            "UmVxdWVzdBJTChBzdHJlYW1pbmdfY29uZmlnGAEgASgLMjcuZ29vZ2xlLmNs",
            "b3VkLnNwZWVjaC52MWJldGExLlN0cmVhbWluZ1JlY29nbml0aW9uQ29uZmln",
            "SAASFwoNYXVkaW9fY29udGVudBgCIAEoDEgAQhMKEXN0cmVhbWluZ19yZXF1",
            "ZXN0Io8BChpTdHJlYW1pbmdSZWNvZ25pdGlvbkNvbmZpZxI+CgZjb25maWcY",
            "ASABKAsyLi5nb29nbGUuY2xvdWQuc3BlZWNoLnYxYmV0YTEuUmVjb2duaXRp",
            "b25Db25maWcSGAoQc2luZ2xlX3V0dGVyYW5jZRgCIAEoCBIXCg9pbnRlcmlt",
            "X3Jlc3VsdHMYAyABKAgi6gIKEVJlY29nbml0aW9uQ29uZmlnEk4KCGVuY29k",
            "aW5nGAEgASgOMjwuZ29vZ2xlLmNsb3VkLnNwZWVjaC52MWJldGExLlJlY29n",
            "bml0aW9uQ29uZmlnLkF1ZGlvRW5jb2RpbmcSEwoLc2FtcGxlX3JhdGUYAiAB",
            "KAUSFQoNbGFuZ3VhZ2VfY29kZRgDIAEoCRIYChBtYXhfYWx0ZXJuYXRpdmVz",
            "GAQgASgFEhgKEHByb2Zhbml0eV9maWx0ZXIYBSABKAgSQgoOc3BlZWNoX2Nv",
            "bnRleHQYBiABKAsyKi5nb29nbGUuY2xvdWQuc3BlZWNoLnYxYmV0YTEuU3Bl",
            "ZWNoQ29udGV4dCJhCg1BdWRpb0VuY29kaW5nEhgKFEVOQ09ESU5HX1VOU1BF",
            "Q0lGSUVEEAASDAoITElORUFSMTYQARIICgRGTEFDEAISCQoFTVVMQVcQAxIH",
            "CgNBTVIQBBIKCgZBTVJfV0IQBSIgCg1TcGVlY2hDb250ZXh0Eg8KB3BocmFz",
            "ZXMYASADKAkiRAoQUmVjb2duaXRpb25BdWRpbxIRCgdjb250ZW50GAEgASgM",
            "SAASDQoDdXJpGAIgASgJSABCDgoMYXVkaW9fc291cmNlIl4KFVN5bmNSZWNv",
            "Z25pemVSZXNwb25zZRJFCgdyZXN1bHRzGAIgAygLMjQuZ29vZ2xlLmNsb3Vk",
            "LnNwZWVjaC52MWJldGExLlNwZWVjaFJlY29nbml0aW9uUmVzdWx0Il8KFkFz",
            "eW5jUmVjb2duaXplUmVzcG9uc2USRQoHcmVzdWx0cxgCIAMoCzI0Lmdvb2ds",
            "ZS5jbG91ZC5zcGVlY2gudjFiZXRhMS5TcGVlY2hSZWNvZ25pdGlvblJlc3Vs",
            "dCKFAwoaU3RyZWFtaW5nUmVjb2duaXplUmVzcG9uc2USIQoFZXJyb3IYASAB",
            "KAsyEi5nb29nbGUucnBjLlN0YXR1cxJICgdyZXN1bHRzGAIgAygLMjcuZ29v",
            "Z2xlLmNsb3VkLnNwZWVjaC52MWJldGExLlN0cmVhbWluZ1JlY29nbml0aW9u",
            "UmVzdWx0EhQKDHJlc3VsdF9pbmRleBgDIAEoBRJfCg9lbmRwb2ludGVyX3R5",
            "cGUYBCABKA4yRi5nb29nbGUuY2xvdWQuc3BlZWNoLnYxYmV0YTEuU3RyZWFt",
            "aW5nUmVjb2duaXplUmVzcG9uc2UuRW5kcG9pbnRlclR5cGUiggEKDkVuZHBv",
            "aW50ZXJUeXBlEiAKHEVORFBPSU5URVJfRVZFTlRfVU5TUEVDSUZJRUQQABIT",
            "Cg9TVEFSVF9PRl9TUEVFQ0gQARIRCg1FTkRfT0ZfU1BFRUNIEAISEAoMRU5E",
            "X09GX0FVRElPEAMSFAoQRU5EX09GX1VUVEVSQU5DRRAEIpIBChpTdHJlYW1p",
            "bmdSZWNvZ25pdGlvblJlc3VsdBJPCgxhbHRlcm5hdGl2ZXMYASADKAsyOS5n",
            "b29nbGUuY2xvdWQuc3BlZWNoLnYxYmV0YTEuU3BlZWNoUmVjb2duaXRpb25B",
            "bHRlcm5hdGl2ZRIQCghpc19maW5hbBgCIAEoCBIRCglzdGFiaWxpdHkYAyAB",
            "KAIiagoXU3BlZWNoUmVjb2duaXRpb25SZXN1bHQSTwoMYWx0ZXJuYXRpdmVz",
            "GAEgAygLMjkuZ29vZ2xlLmNsb3VkLnNwZWVjaC52MWJldGExLlNwZWVjaFJl",
            "Y29nbml0aW9uQWx0ZXJuYXRpdmUiRgocU3BlZWNoUmVjb2duaXRpb25BbHRl",
            "cm5hdGl2ZRISCgp0cmFuc2NyaXB0GAEgASgJEhIKCmNvbmZpZGVuY2UYAiAB",
            "KAIyyAMKBlNwZWVjaBKgAQoNU3luY1JlY29nbml6ZRIxLmdvb2dsZS5jbG91",
            "ZC5zcGVlY2gudjFiZXRhMS5TeW5jUmVjb2duaXplUmVxdWVzdBoyLmdvb2ds",
            "ZS5jbG91ZC5zcGVlY2gudjFiZXRhMS5TeW5jUmVjb2duaXplUmVzcG9uc2Ui",
            "KILT5JMCIiIdL3YxYmV0YTEvc3BlZWNoOnN5bmNyZWNvZ25pemU6ASoSjgEK",
            "DkFzeW5jUmVjb2duaXplEjIuZ29vZ2xlLmNsb3VkLnNwZWVjaC52MWJldGEx",
            "LkFzeW5jUmVjb2duaXplUmVxdWVzdBodLmdvb2dsZS5sb25ncnVubmluZy5P",
            "cGVyYXRpb24iKYLT5JMCIyIeL3YxYmV0YTEvc3BlZWNoOmFzeW5jcmVjb2du",
            "aXplOgEqEokBChJTdHJlYW1pbmdSZWNvZ25pemUSNi5nb29nbGUuY2xvdWQu",
            "c3BlZWNoLnYxYmV0YTEuU3RyZWFtaW5nUmVjb2duaXplUmVxdWVzdBo3Lmdv",
            "b2dsZS5jbG91ZC5zcGVlY2gudjFiZXRhMS5TdHJlYW1pbmdSZWNvZ25pemVS",
            "ZXNwb25zZSgBMAFCMAofY29tLmdvb2dsZS5jbG91ZC5zcGVlY2gudjFiZXRh",
            "MUILU3BlZWNoUHJvdG9QAWIGcHJvdG8z"));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.AnnotationsReflection.Descriptor, global::Google.Longrunning.OperationsReflection.Descriptor, global::Google.Rpc.StatusReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.SyncRecognizeRequest), global::Google.Cloud.Speech.V1Beta1.SyncRecognizeRequest.Parser, new[]{ "Config", "Audio" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.AsyncRecognizeRequest), global::Google.Cloud.Speech.V1Beta1.AsyncRecognizeRequest.Parser, new[]{ "Config", "Audio" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeRequest), global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeRequest.Parser, new[]{ "StreamingConfig", "AudioContent" }, new[]{ "StreamingRequest" }, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionConfig), global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionConfig.Parser, new[]{ "Config", "SingleUtterance", "InterimResults" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.RecognitionConfig), global::Google.Cloud.Speech.V1Beta1.RecognitionConfig.Parser, new[]{ "Encoding", "SampleRate", "LanguageCode", "MaxAlternatives", "ProfanityFilter", "SpeechContext" }, null, new[]{ typeof(global::Google.Cloud.Speech.V1Beta1.RecognitionConfig.Types.AudioEncoding) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.SpeechContext), global::Google.Cloud.Speech.V1Beta1.SpeechContext.Parser, new[]{ "Phrases" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.RecognitionAudio), global::Google.Cloud.Speech.V1Beta1.RecognitionAudio.Parser, new[]{ "Content", "Uri" }, new[]{ "AudioSource" }, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.SyncRecognizeResponse), global::Google.Cloud.Speech.V1Beta1.SyncRecognizeResponse.Parser, new[]{ "Results" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.AsyncRecognizeResponse), global::Google.Cloud.Speech.V1Beta1.AsyncRecognizeResponse.Parser, new[]{ "Results" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeResponse), global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeResponse.Parser, new[]{ "Error", "Results", "ResultIndex", "EndpointerType" }, null, new[]{ typeof(global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeResponse.Types.EndpointerType) }, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionResult), global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionResult.Parser, new[]{ "Alternatives", "IsFinal", "Stability" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult), global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult.Parser, new[]{ "Alternatives" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative), global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative.Parser, new[]{ "Transcript", "Confidence" }, null, null, null)
          }));
    }
    #endregion

  }
  #region Messages
  /// <summary>
  /// `SyncRecognizeRequest` is the top-level message sent by the client for
  /// the `SyncRecognize` method.
  /// </summary>
  public sealed partial class SyncRecognizeRequest : pb::IMessage<SyncRecognizeRequest> {
    private static readonly pb::MessageParser<SyncRecognizeRequest> _parser = new pb::MessageParser<SyncRecognizeRequest>(() => new SyncRecognizeRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SyncRecognizeRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SyncRecognizeRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SyncRecognizeRequest(SyncRecognizeRequest other) : this() {
      Config = other.config_ != null ? other.Config.Clone() : null;
      Audio = other.audio_ != null ? other.Audio.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SyncRecognizeRequest Clone() {
      return new SyncRecognizeRequest(this);
    }

    /// <summary>Field number for the "config" field.</summary>
    public const int ConfigFieldNumber = 1;
    private global::Google.Cloud.Speech.V1Beta1.RecognitionConfig config_;
    /// <summary>
    /// [Required] The `config` message provides information to the recognizer
    /// that specifies how to process the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.RecognitionConfig Config {
      get { return config_; }
      set {
        config_ = value;
      }
    }

    /// <summary>Field number for the "audio" field.</summary>
    public const int AudioFieldNumber = 2;
    private global::Google.Cloud.Speech.V1Beta1.RecognitionAudio audio_;
    /// <summary>
    /// [Required] The audio data to be recognized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.RecognitionAudio Audio {
      get { return audio_; }
      set {
        audio_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SyncRecognizeRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SyncRecognizeRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Config, other.Config)) return false;
      if (!object.Equals(Audio, other.Audio)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (config_ != null) hash ^= Config.GetHashCode();
      if (audio_ != null) hash ^= Audio.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (audio_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Audio);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (config_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Config);
      }
      if (audio_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Audio);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SyncRecognizeRequest other) {
      if (other == null) {
        return;
      }
      if (other.config_ != null) {
        if (config_ == null) {
          config_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionConfig();
        }
        Config.MergeFrom(other.Config);
      }
      if (other.audio_ != null) {
        if (audio_ == null) {
          audio_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionAudio();
        }
        Audio.MergeFrom(other.Audio);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (config_ == null) {
              config_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionConfig();
            }
            input.ReadMessage(config_);
            break;
          }
          case 18: {
            if (audio_ == null) {
              audio_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionAudio();
            }
            input.ReadMessage(audio_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// `AsyncRecognizeRequest` is the top-level message sent by the client for
  /// the `AsyncRecognize` method.
  /// </summary>
  public sealed partial class AsyncRecognizeRequest : pb::IMessage<AsyncRecognizeRequest> {
    private static readonly pb::MessageParser<AsyncRecognizeRequest> _parser = new pb::MessageParser<AsyncRecognizeRequest>(() => new AsyncRecognizeRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<AsyncRecognizeRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AsyncRecognizeRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AsyncRecognizeRequest(AsyncRecognizeRequest other) : this() {
      Config = other.config_ != null ? other.Config.Clone() : null;
      Audio = other.audio_ != null ? other.Audio.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AsyncRecognizeRequest Clone() {
      return new AsyncRecognizeRequest(this);
    }

    /// <summary>Field number for the "config" field.</summary>
    public const int ConfigFieldNumber = 1;
    private global::Google.Cloud.Speech.V1Beta1.RecognitionConfig config_;
    /// <summary>
    /// [Required] The `config` message provides information to the recognizer
    /// that specifies how to process the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.RecognitionConfig Config {
      get { return config_; }
      set {
        config_ = value;
      }
    }

    /// <summary>Field number for the "audio" field.</summary>
    public const int AudioFieldNumber = 2;
    private global::Google.Cloud.Speech.V1Beta1.RecognitionAudio audio_;
    /// <summary>
    /// [Required] The audio data to be recognized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.RecognitionAudio Audio {
      get { return audio_; }
      set {
        audio_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as AsyncRecognizeRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(AsyncRecognizeRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Config, other.Config)) return false;
      if (!object.Equals(Audio, other.Audio)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (config_ != null) hash ^= Config.GetHashCode();
      if (audio_ != null) hash ^= Audio.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (audio_ != null) {
        output.WriteRawTag(18);
        output.WriteMessage(Audio);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (config_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Config);
      }
      if (audio_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Audio);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(AsyncRecognizeRequest other) {
      if (other == null) {
        return;
      }
      if (other.config_ != null) {
        if (config_ == null) {
          config_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionConfig();
        }
        Config.MergeFrom(other.Config);
      }
      if (other.audio_ != null) {
        if (audio_ == null) {
          audio_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionAudio();
        }
        Audio.MergeFrom(other.Audio);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (config_ == null) {
              config_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionConfig();
            }
            input.ReadMessage(config_);
            break;
          }
          case 18: {
            if (audio_ == null) {
              audio_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionAudio();
            }
            input.ReadMessage(audio_);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// `StreamingRecognizeRequest` is the top-level message sent by the client for
  /// the `StreamingRecognize`. Multiple `StreamingRecognizeRequest` messages are
  /// sent. The first message must contain a `streaming_config` message and must
  /// not contain `audio` data. All subsequent messages must contain `audio` data
  /// and must not contain a `streaming_config` message.
  /// </summary>
  public sealed partial class StreamingRecognizeRequest : pb::IMessage<StreamingRecognizeRequest> {
    private static readonly pb::MessageParser<StreamingRecognizeRequest> _parser = new pb::MessageParser<StreamingRecognizeRequest>(() => new StreamingRecognizeRequest());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognizeRequest> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeRequest() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeRequest(StreamingRecognizeRequest other) : this() {
      switch (other.StreamingRequestCase) {
        case StreamingRequestOneofCase.StreamingConfig:
          StreamingConfig = other.StreamingConfig.Clone();
          break;
        case StreamingRequestOneofCase.AudioContent:
          AudioContent = other.AudioContent;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeRequest Clone() {
      return new StreamingRecognizeRequest(this);
    }

    /// <summary>Field number for the "streaming_config" field.</summary>
    public const int StreamingConfigFieldNumber = 1;
    /// <summary>
    /// The `streaming_config` message provides information to the recognizer
    /// that specifies how to process the request.
    ///
    /// The first `StreamingRecognizeRequest` message must contain a
    /// `streaming_config`  message.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionConfig StreamingConfig {
      get { return streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig ? (global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionConfig) streamingRequest_ : null; }
      set {
        streamingRequest_ = value;
        streamingRequestCase_ = value == null ? StreamingRequestOneofCase.None : StreamingRequestOneofCase.StreamingConfig;
      }
    }

    /// <summary>Field number for the "audio_content" field.</summary>
    public const int AudioContentFieldNumber = 2;
    /// <summary>
    /// The audio data to be recognized. Sequential chunks of audio data are sent
    /// in sequential `StreamingRecognizeRequest` messages. The first
    /// `StreamingRecognizeRequest` message must not contain `audio_content` data
    /// and all subsequent `StreamingRecognizeRequest` messages must contain
    /// `audio_content` data. The audio bytes must be encoded as specified in
    /// `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
    /// pure binary representation (not base64).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString AudioContent {
      get { return streamingRequestCase_ == StreamingRequestOneofCase.AudioContent ? (pb::ByteString) streamingRequest_ : pb::ByteString.Empty; }
      set {
        streamingRequest_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        streamingRequestCase_ = StreamingRequestOneofCase.AudioContent;
      }
    }

    private object streamingRequest_;
    /// <summary>Enum of possible cases for the "streaming_request" oneof.</summary>
    public enum StreamingRequestOneofCase {
      None = 0,
      StreamingConfig = 1,
      AudioContent = 2,
    }
    private StreamingRequestOneofCase streamingRequestCase_ = StreamingRequestOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRequestOneofCase StreamingRequestCase {
      get { return streamingRequestCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearStreamingRequest() {
      streamingRequestCase_ = StreamingRequestOneofCase.None;
      streamingRequest_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognizeRequest);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognizeRequest other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(StreamingConfig, other.StreamingConfig)) return false;
      if (AudioContent != other.AudioContent) return false;
      if (StreamingRequestCase != other.StreamingRequestCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) hash ^= StreamingConfig.GetHashCode();
      if (streamingRequestCase_ == StreamingRequestOneofCase.AudioContent) hash ^= AudioContent.GetHashCode();
      hash ^= (int) streamingRequestCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
        output.WriteRawTag(10);
        output.WriteMessage(StreamingConfig);
      }
      if (streamingRequestCase_ == StreamingRequestOneofCase.AudioContent) {
        output.WriteRawTag(18);
        output.WriteBytes(AudioContent);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(StreamingConfig);
      }
      if (streamingRequestCase_ == StreamingRequestOneofCase.AudioContent) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(AudioContent);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognizeRequest other) {
      if (other == null) {
        return;
      }
      switch (other.StreamingRequestCase) {
        case StreamingRequestOneofCase.StreamingConfig:
          StreamingConfig = other.StreamingConfig;
          break;
        case StreamingRequestOneofCase.AudioContent:
          AudioContent = other.AudioContent;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionConfig subBuilder = new global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionConfig();
            if (streamingRequestCase_ == StreamingRequestOneofCase.StreamingConfig) {
              subBuilder.MergeFrom(StreamingConfig);
            }
            input.ReadMessage(subBuilder);
            StreamingConfig = subBuilder;
            break;
          }
          case 18: {
            AudioContent = input.ReadBytes();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// The `StreamingRecognitionConfig` message provides information to the
  /// recognizer that specifies how to process the request.
  /// </summary>
  public sealed partial class StreamingRecognitionConfig : pb::IMessage<StreamingRecognitionConfig> {
    private static readonly pb::MessageParser<StreamingRecognitionConfig> _parser = new pb::MessageParser<StreamingRecognitionConfig>(() => new StreamingRecognitionConfig());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognitionConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[3]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionConfig(StreamingRecognitionConfig other) : this() {
      Config = other.config_ != null ? other.Config.Clone() : null;
      singleUtterance_ = other.singleUtterance_;
      interimResults_ = other.interimResults_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionConfig Clone() {
      return new StreamingRecognitionConfig(this);
    }

    /// <summary>Field number for the "config" field.</summary>
    public const int ConfigFieldNumber = 1;
    private global::Google.Cloud.Speech.V1Beta1.RecognitionConfig config_;
    /// <summary>
    /// [Required] The `config` message provides information to the recognizer
    /// that specifies how to process the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.RecognitionConfig Config {
      get { return config_; }
      set {
        config_ = value;
      }
    }

    /// <summary>Field number for the "single_utterance" field.</summary>
    public const int SingleUtteranceFieldNumber = 2;
    private bool singleUtterance_;
    /// <summary>
    /// [Optional] If `false` or omitted, the recognizer will perform continuous
    /// recognition (continuing to process audio even if the user pauses speaking)
    /// until the client closes the output stream (gRPC API) or when the maximum
    /// time limit has been reached. Multiple `SpeechRecognitionResult`s with the
    /// `is_final` flag set to `true` may be returned.
    ///
    /// If `true`, the recognizer will detect a single spoken utterance. When it
    /// detects that the user has paused or stopped speaking, it will return an
    /// `END_OF_UTTERANCE` event and cease recognition. It will return no more than
    /// one `SpeechRecognitionResult` with the `is_final` flag set to `true`.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool SingleUtterance {
      get { return singleUtterance_; }
      set {
        singleUtterance_ = value;
      }
    }

    /// <summary>Field number for the "interim_results" field.</summary>
    public const int InterimResultsFieldNumber = 3;
    private bool interimResults_;
    /// <summary>
    /// [Optional] If `true`, interim results (tentative hypotheses) may be
    /// returned as they become available (these interim results are indicated with
    /// the `is_final=false` flag).
    /// If `false` or omitted, only `is_final=true` result(s) are returned.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool InterimResults {
      get { return interimResults_; }
      set {
        interimResults_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognitionConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognitionConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Config, other.Config)) return false;
      if (SingleUtterance != other.SingleUtterance) return false;
      if (InterimResults != other.InterimResults) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (config_ != null) hash ^= Config.GetHashCode();
      if (SingleUtterance != false) hash ^= SingleUtterance.GetHashCode();
      if (InterimResults != false) hash ^= InterimResults.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (config_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Config);
      }
      if (SingleUtterance != false) {
        output.WriteRawTag(16);
        output.WriteBool(SingleUtterance);
      }
      if (InterimResults != false) {
        output.WriteRawTag(24);
        output.WriteBool(InterimResults);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (config_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Config);
      }
      if (SingleUtterance != false) {
        size += 1 + 1;
      }
      if (InterimResults != false) {
        size += 1 + 1;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognitionConfig other) {
      if (other == null) {
        return;
      }
      if (other.config_ != null) {
        if (config_ == null) {
          config_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionConfig();
        }
        Config.MergeFrom(other.Config);
      }
      if (other.SingleUtterance != false) {
        SingleUtterance = other.SingleUtterance;
      }
      if (other.InterimResults != false) {
        InterimResults = other.InterimResults;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (config_ == null) {
              config_ = new global::Google.Cloud.Speech.V1Beta1.RecognitionConfig();
            }
            input.ReadMessage(config_);
            break;
          }
          case 16: {
            SingleUtterance = input.ReadBool();
            break;
          }
          case 24: {
            InterimResults = input.ReadBool();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// The `RecognitionConfig` message provides information to the recognizer
  /// that specifies how to process the request.
  /// </summary>
  public sealed partial class RecognitionConfig : pb::IMessage<RecognitionConfig> {
    private static readonly pb::MessageParser<RecognitionConfig> _parser = new pb::MessageParser<RecognitionConfig>(() => new RecognitionConfig());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RecognitionConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[4]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionConfig(RecognitionConfig other) : this() {
      encoding_ = other.encoding_;
      sampleRate_ = other.sampleRate_;
      languageCode_ = other.languageCode_;
      maxAlternatives_ = other.maxAlternatives_;
      profanityFilter_ = other.profanityFilter_;
      SpeechContext = other.speechContext_ != null ? other.SpeechContext.Clone() : null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionConfig Clone() {
      return new RecognitionConfig(this);
    }

    /// <summary>Field number for the "encoding" field.</summary>
    public const int EncodingFieldNumber = 1;
    private global::Google.Cloud.Speech.V1Beta1.RecognitionConfig.Types.AudioEncoding encoding_ = 0;
    /// <summary>
    /// [Required] Encoding of audio data sent in all `RecognitionAudio` messages.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.RecognitionConfig.Types.AudioEncoding Encoding {
      get { return encoding_; }
      set {
        encoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate" field.</summary>
    public const int SampleRateFieldNumber = 2;
    private int sampleRate_;
    /// <summary>
    /// [Required] Sample rate in Hertz of the audio data sent in all
    /// `RecognitionAudio` messages. Valid values are: 8000-48000.
    /// 16000 is optimal. For best results, set the sampling rate of the audio
    /// source to 16000 Hz. If that's not possible, use the native sample rate of
    /// the audio source (instead of re-sampling).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRate {
      get { return sampleRate_; }
      set {
        sampleRate_ = value;
      }
    }

    /// <summary>Field number for the "language_code" field.</summary>
    public const int LanguageCodeFieldNumber = 3;
    private string languageCode_ = "";
    /// <summary>
    /// [Optional] The language of the supplied audio as a BCP-47 language tag.
    /// Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
    /// If omitted, defaults to "en-US". See
    /// [Language Support](/speech/docs/best-practices#language_support) for
    /// a list of the currently supported language codes.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string LanguageCode {
      get { return languageCode_; }
      set {
        languageCode_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "max_alternatives" field.</summary>
    public const int MaxAlternativesFieldNumber = 4;
    private int maxAlternatives_;
    /// <summary>
    /// [Optional] Maximum number of recognition hypotheses to be returned.
    /// Specifically, the maximum number of `SpeechRecognitionAlternative` messages
    /// within each `SpeechRecognitionResult`.
    /// The server may return fewer than `max_alternatives`.
    /// Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
    /// `1`. If omitted, defaults to `1`.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int MaxAlternatives {
      get { return maxAlternatives_; }
      set {
        maxAlternatives_ = value;
      }
    }

    /// <summary>Field number for the "profanity_filter" field.</summary>
    public const int ProfanityFilterFieldNumber = 5;
    private bool profanityFilter_;
    /// <summary>
    /// [Optional] If set to `true`, the server will attempt to filter out
    /// profanities, replacing all but the initial character in each filtered word
    /// with asterisks, e.g. "f***". If set to `false` or omitted, profanities
    /// won't be filtered out.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool ProfanityFilter {
      get { return profanityFilter_; }
      set {
        profanityFilter_ = value;
      }
    }

    /// <summary>Field number for the "speech_context" field.</summary>
    public const int SpeechContextFieldNumber = 6;
    private global::Google.Cloud.Speech.V1Beta1.SpeechContext speechContext_;
    /// <summary>
    /// [Optional] A means to provide context to assist the speech recognition.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.SpeechContext SpeechContext {
      get { return speechContext_; }
      set {
        speechContext_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RecognitionConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RecognitionConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Encoding != other.Encoding) return false;
      if (SampleRate != other.SampleRate) return false;
      if (LanguageCode != other.LanguageCode) return false;
      if (MaxAlternatives != other.MaxAlternatives) return false;
      if (ProfanityFilter != other.ProfanityFilter) return false;
      if (!object.Equals(SpeechContext, other.SpeechContext)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Encoding != 0) hash ^= Encoding.GetHashCode();
      if (SampleRate != 0) hash ^= SampleRate.GetHashCode();
      if (LanguageCode.Length != 0) hash ^= LanguageCode.GetHashCode();
      if (MaxAlternatives != 0) hash ^= MaxAlternatives.GetHashCode();
      if (ProfanityFilter != false) hash ^= ProfanityFilter.GetHashCode();
      if (speechContext_ != null) hash ^= SpeechContext.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (Encoding != 0) {
        output.WriteRawTag(8);
        output.WriteEnum((int) Encoding);
      }
      if (SampleRate != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRate);
      }
      if (LanguageCode.Length != 0) {
        output.WriteRawTag(26);
        output.WriteString(LanguageCode);
      }
      if (MaxAlternatives != 0) {
        output.WriteRawTag(32);
        output.WriteInt32(MaxAlternatives);
      }
      if (ProfanityFilter != false) {
        output.WriteRawTag(40);
        output.WriteBool(ProfanityFilter);
      }
      if (speechContext_ != null) {
        output.WriteRawTag(50);
        output.WriteMessage(SpeechContext);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Encoding != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) Encoding);
      }
      if (SampleRate != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRate);
      }
      if (LanguageCode.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(LanguageCode);
      }
      if (MaxAlternatives != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(MaxAlternatives);
      }
      if (ProfanityFilter != false) {
        size += 1 + 1;
      }
      if (speechContext_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(SpeechContext);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RecognitionConfig other) {
      if (other == null) {
        return;
      }
      if (other.Encoding != 0) {
        Encoding = other.Encoding;
      }
      if (other.SampleRate != 0) {
        SampleRate = other.SampleRate;
      }
      if (other.LanguageCode.Length != 0) {
        LanguageCode = other.LanguageCode;
      }
      if (other.MaxAlternatives != 0) {
        MaxAlternatives = other.MaxAlternatives;
      }
      if (other.ProfanityFilter != false) {
        ProfanityFilter = other.ProfanityFilter;
      }
      if (other.speechContext_ != null) {
        if (speechContext_ == null) {
          speechContext_ = new global::Google.Cloud.Speech.V1Beta1.SpeechContext();
        }
        SpeechContext.MergeFrom(other.SpeechContext);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 8: {
            encoding_ = (global::Google.Cloud.Speech.V1Beta1.RecognitionConfig.Types.AudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRate = input.ReadInt32();
            break;
          }
          case 26: {
            LanguageCode = input.ReadString();
            break;
          }
          case 32: {
            MaxAlternatives = input.ReadInt32();
            break;
          }
          case 40: {
            ProfanityFilter = input.ReadBool();
            break;
          }
          case 50: {
            if (speechContext_ == null) {
              speechContext_ = new global::Google.Cloud.Speech.V1Beta1.SpeechContext();
            }
            input.ReadMessage(speechContext_);
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the RecognitionConfig message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Audio encoding of the data sent in the audio message. All encodings support
      /// only 1 channel (mono) audio. Only `FLAC` includes a header that describes
      /// the bytes of audio that follow the header. The other encodings are raw
      /// audio bytes with no header.
      ///
      /// For best results, the audio source should be captured and transmitted using
      /// a lossless encoding (`FLAC` or `LINEAR16`). Recognition accuracy may be
      /// reduced if lossy codecs (such as AMR, AMR_WB and MULAW) are used to capture
      /// or transmit the audio, particularly if background noise is present.
      /// </summary>
      public enum AudioEncoding {
        /// <summary>
        /// Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
        /// </summary>
        [pbr::OriginalName("ENCODING_UNSPECIFIED")] EncodingUnspecified = 0,
        /// <summary>
        /// Uncompressed 16-bit signed little-endian samples.
        /// This is the only encoding that may be used by `AsyncRecognize`.
        /// </summary>
        [pbr::OriginalName("LINEAR16")] Linear16 = 1,
        /// <summary>
        /// This is the recommended encoding for `SyncRecognize` and
        /// `StreamingRecognize` because it uses lossless compression; therefore
        /// recognition accuracy is not compromised by a lossy codec.
        ///
        /// The stream FLAC (Free Lossless Audio Codec) encoding is specified at:
        /// http://flac.sourceforge.net/documentation.html.
        /// Only 16-bit samples are supported.
        /// Not all fields in STREAMINFO are supported.
        /// </summary>
        [pbr::OriginalName("FLAC")] Flac = 2,
        /// <summary>
        /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
        /// </summary>
        [pbr::OriginalName("MULAW")] Mulaw = 3,
        /// <summary>
        /// Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.
        /// </summary>
        [pbr::OriginalName("AMR")] Amr = 4,
        /// <summary>
        /// Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.
        /// </summary>
        [pbr::OriginalName("AMR_WB")] AmrWb = 5,
      }

    }
    #endregion

  }

  /// <summary>
  /// Provides "hints" to the speech recognizer to favor specific words and phrases
  /// in the results.
  /// </summary>
  public sealed partial class SpeechContext : pb::IMessage<SpeechContext> {
    private static readonly pb::MessageParser<SpeechContext> _parser = new pb::MessageParser<SpeechContext>(() => new SpeechContext());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechContext> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[5]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext(SpeechContext other) : this() {
      phrases_ = other.phrases_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechContext Clone() {
      return new SpeechContext(this);
    }

    /// <summary>Field number for the "phrases" field.</summary>
    public const int PhrasesFieldNumber = 1;
    private static readonly pb::FieldCodec<string> _repeated_phrases_codec
        = pb::FieldCodec.ForString(10);
    private readonly pbc::RepeatedField<string> phrases_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// [Optional] A list of up to 50 phrases of up to 100 characters each to
    /// provide words and phrases "hints" to the speech recognition so that it is
    /// more likely to recognize them.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> Phrases {
      get { return phrases_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechContext);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechContext other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!phrases_.Equals(other.phrases_)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= phrases_.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      phrases_.WriteTo(output, _repeated_phrases_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += phrases_.CalculateSize(_repeated_phrases_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechContext other) {
      if (other == null) {
        return;
      }
      phrases_.Add(other.phrases_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            phrases_.AddEntriesFrom(input, _repeated_phrases_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Contains audio data in the encoding specified in the `RecognitionConfig`.
  /// Either `content` or `uri` must be supplied. Supplying both or neither
  /// returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
  /// </summary>
  public sealed partial class RecognitionAudio : pb::IMessage<RecognitionAudio> {
    private static readonly pb::MessageParser<RecognitionAudio> _parser = new pb::MessageParser<RecognitionAudio>(() => new RecognitionAudio());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<RecognitionAudio> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[6]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionAudio() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionAudio(RecognitionAudio other) : this() {
      switch (other.AudioSourceCase) {
        case AudioSourceOneofCase.Content:
          Content = other.Content;
          break;
        case AudioSourceOneofCase.Uri:
          Uri = other.Uri;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public RecognitionAudio Clone() {
      return new RecognitionAudio(this);
    }

    /// <summary>Field number for the "content" field.</summary>
    public const int ContentFieldNumber = 1;
    /// <summary>
    /// The audio data bytes encoded as specified in
    /// `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
    /// pure binary representation, whereas JSON representations use base64.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pb::ByteString Content {
      get { return audioSourceCase_ == AudioSourceOneofCase.Content ? (pb::ByteString) audioSource_ : pb::ByteString.Empty; }
      set {
        audioSource_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        audioSourceCase_ = AudioSourceOneofCase.Content;
      }
    }

    /// <summary>Field number for the "uri" field.</summary>
    public const int UriFieldNumber = 2;
    /// <summary>
    /// URI that points to a file that contains audio data bytes as specified in
    /// `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
    /// supported, which must be specified in the following format:
    /// `gs://bucket_name/object_name` (other URI formats return
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For more information, see
    /// [Request URIs](/storage/docs/reference-uris).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Uri {
      get { return audioSourceCase_ == AudioSourceOneofCase.Uri ? (string) audioSource_ : ""; }
      set {
        audioSource_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
        audioSourceCase_ = AudioSourceOneofCase.Uri;
      }
    }

    private object audioSource_;
    /// <summary>Enum of possible cases for the "audio_source" oneof.</summary>
    public enum AudioSourceOneofCase {
      None = 0,
      Content = 1,
      Uri = 2,
    }
    private AudioSourceOneofCase audioSourceCase_ = AudioSourceOneofCase.None;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AudioSourceOneofCase AudioSourceCase {
      get { return audioSourceCase_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void ClearAudioSource() {
      audioSourceCase_ = AudioSourceOneofCase.None;
      audioSource_ = null;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as RecognitionAudio);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(RecognitionAudio other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Content != other.Content) return false;
      if (Uri != other.Uri) return false;
      if (AudioSourceCase != other.AudioSourceCase) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (audioSourceCase_ == AudioSourceOneofCase.Content) hash ^= Content.GetHashCode();
      if (audioSourceCase_ == AudioSourceOneofCase.Uri) hash ^= Uri.GetHashCode();
      hash ^= (int) audioSourceCase_;
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (audioSourceCase_ == AudioSourceOneofCase.Content) {
        output.WriteRawTag(10);
        output.WriteBytes(Content);
      }
      if (audioSourceCase_ == AudioSourceOneofCase.Uri) {
        output.WriteRawTag(18);
        output.WriteString(Uri);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (audioSourceCase_ == AudioSourceOneofCase.Content) {
        size += 1 + pb::CodedOutputStream.ComputeBytesSize(Content);
      }
      if (audioSourceCase_ == AudioSourceOneofCase.Uri) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Uri);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(RecognitionAudio other) {
      if (other == null) {
        return;
      }
      switch (other.AudioSourceCase) {
        case AudioSourceOneofCase.Content:
          Content = other.Content;
          break;
        case AudioSourceOneofCase.Uri:
          Uri = other.Uri;
          break;
      }

    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            Content = input.ReadBytes();
            break;
          }
          case 18: {
            Uri = input.ReadString();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// `SyncRecognizeResponse` is the only message returned to the client by
  /// `SyncRecognize`. It contains the result as zero or more
  /// sequential `RecognizeResponse` messages.
  /// </summary>
  public sealed partial class SyncRecognizeResponse : pb::IMessage<SyncRecognizeResponse> {
    private static readonly pb::MessageParser<SyncRecognizeResponse> _parser = new pb::MessageParser<SyncRecognizeResponse>(() => new SyncRecognizeResponse());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SyncRecognizeResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[7]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SyncRecognizeResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SyncRecognizeResponse(SyncRecognizeResponse other) : this() {
      results_ = other.results_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SyncRecognizeResponse Clone() {
      return new SyncRecognizeResponse(this);
    }

    /// <summary>Field number for the "results" field.</summary>
    public const int ResultsFieldNumber = 2;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult> _repeated_results_codec
        = pb::FieldCodec.ForMessage(18, global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult> results_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult>();
    /// <summary>
    /// [Output-only] Sequential list of transcription results corresponding to
    /// sequential portions of audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult> Results {
      get { return results_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SyncRecognizeResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SyncRecognizeResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!results_.Equals(other.results_)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= results_.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      results_.WriteTo(output, _repeated_results_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += results_.CalculateSize(_repeated_results_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SyncRecognizeResponse other) {
      if (other == null) {
        return;
      }
      results_.Add(other.results_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 18: {
            results_.AddEntriesFrom(input, _repeated_results_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// `AsyncRecognizeResponse` is the only message returned to the client by
  /// `AsyncRecognize`. It contains the result as zero or more
  /// sequential `RecognizeResponse` messages.
  /// </summary>
  public sealed partial class AsyncRecognizeResponse : pb::IMessage<AsyncRecognizeResponse> {
    private static readonly pb::MessageParser<AsyncRecognizeResponse> _parser = new pb::MessageParser<AsyncRecognizeResponse>(() => new AsyncRecognizeResponse());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<AsyncRecognizeResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[8]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AsyncRecognizeResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AsyncRecognizeResponse(AsyncRecognizeResponse other) : this() {
      results_ = other.results_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public AsyncRecognizeResponse Clone() {
      return new AsyncRecognizeResponse(this);
    }

    /// <summary>Field number for the "results" field.</summary>
    public const int ResultsFieldNumber = 2;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult> _repeated_results_codec
        = pb::FieldCodec.ForMessage(18, global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult> results_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult>();
    /// <summary>
    /// [Output-only] Sequential list of transcription results corresponding to
    /// sequential portions of audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionResult> Results {
      get { return results_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as AsyncRecognizeResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(AsyncRecognizeResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!results_.Equals(other.results_)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= results_.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      results_.WriteTo(output, _repeated_results_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += results_.CalculateSize(_repeated_results_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(AsyncRecognizeResponse other) {
      if (other == null) {
        return;
      }
      results_.Add(other.results_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 18: {
            results_.AddEntriesFrom(input, _repeated_results_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// `StreamingRecognizeResponse` is the only message returned to the client by
  /// `StreamingRecognize`. It contains the result as zero or more
  /// sequential `RecognizeResponse` messages.
  /// </summary>
  public sealed partial class StreamingRecognizeResponse : pb::IMessage<StreamingRecognizeResponse> {
    private static readonly pb::MessageParser<StreamingRecognizeResponse> _parser = new pb::MessageParser<StreamingRecognizeResponse>(() => new StreamingRecognizeResponse());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognizeResponse> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[9]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeResponse() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeResponse(StreamingRecognizeResponse other) : this() {
      Error = other.error_ != null ? other.Error.Clone() : null;
      results_ = other.results_.Clone();
      resultIndex_ = other.resultIndex_;
      endpointerType_ = other.endpointerType_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognizeResponse Clone() {
      return new StreamingRecognizeResponse(this);
    }

    /// <summary>Field number for the "error" field.</summary>
    public const int ErrorFieldNumber = 1;
    private global::Google.Rpc.Status error_;
    /// <summary>
    /// [Output-only] If set, returns a [google.rpc.Status][] message that
    /// specifies the error for the operation.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Rpc.Status Error {
      get { return error_; }
      set {
        error_ = value;
      }
    }

    /// <summary>Field number for the "results" field.</summary>
    public const int ResultsFieldNumber = 2;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionResult> _repeated_results_codec
        = pb::FieldCodec.ForMessage(18, global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionResult.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionResult> results_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionResult>();
    /// <summary>
    /// [Output-only] This repeated list contains zero or more results that
    /// correspond to consecutive portions of the audio currently being processed.
    /// It contains zero or one `is_final=true` result (the newly settled portion),
    /// followed by zero or more `is_final=false` results.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.StreamingRecognitionResult> Results {
      get { return results_; }
    }

    /// <summary>Field number for the "result_index" field.</summary>
    public const int ResultIndexFieldNumber = 3;
    private int resultIndex_;
    /// <summary>
    /// [Output-only] Indicates the lowest index in the `results` array that has
    /// changed. The repeated `SpeechRecognitionResult` results overwrite past
    /// results at this index and higher.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int ResultIndex {
      get { return resultIndex_; }
      set {
        resultIndex_ = value;
      }
    }

    /// <summary>Field number for the "endpointer_type" field.</summary>
    public const int EndpointerTypeFieldNumber = 4;
    private global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeResponse.Types.EndpointerType endpointerType_ = 0;
    /// <summary>
    /// [Output-only] Indicates the type of endpointer event.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeResponse.Types.EndpointerType EndpointerType {
      get { return endpointerType_; }
      set {
        endpointerType_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognizeResponse);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognizeResponse other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!object.Equals(Error, other.Error)) return false;
      if(!results_.Equals(other.results_)) return false;
      if (ResultIndex != other.ResultIndex) return false;
      if (EndpointerType != other.EndpointerType) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (error_ != null) hash ^= Error.GetHashCode();
      hash ^= results_.GetHashCode();
      if (ResultIndex != 0) hash ^= ResultIndex.GetHashCode();
      if (EndpointerType != 0) hash ^= EndpointerType.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (error_ != null) {
        output.WriteRawTag(10);
        output.WriteMessage(Error);
      }
      results_.WriteTo(output, _repeated_results_codec);
      if (ResultIndex != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(ResultIndex);
      }
      if (EndpointerType != 0) {
        output.WriteRawTag(32);
        output.WriteEnum((int) EndpointerType);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (error_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Error);
      }
      size += results_.CalculateSize(_repeated_results_codec);
      if (ResultIndex != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(ResultIndex);
      }
      if (EndpointerType != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) EndpointerType);
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognizeResponse other) {
      if (other == null) {
        return;
      }
      if (other.error_ != null) {
        if (error_ == null) {
          error_ = new global::Google.Rpc.Status();
        }
        Error.MergeFrom(other.Error);
      }
      results_.Add(other.results_);
      if (other.ResultIndex != 0) {
        ResultIndex = other.ResultIndex;
      }
      if (other.EndpointerType != 0) {
        EndpointerType = other.EndpointerType;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            if (error_ == null) {
              error_ = new global::Google.Rpc.Status();
            }
            input.ReadMessage(error_);
            break;
          }
          case 18: {
            results_.AddEntriesFrom(input, _repeated_results_codec);
            break;
          }
          case 24: {
            ResultIndex = input.ReadInt32();
            break;
          }
          case 32: {
            endpointerType_ = (global::Google.Cloud.Speech.V1Beta1.StreamingRecognizeResponse.Types.EndpointerType) input.ReadEnum();
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the StreamingRecognizeResponse message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Indicates the type of endpointer event.
      /// </summary>
      public enum EndpointerType {
        /// <summary>
        /// No endpointer event specified.
        /// </summary>
        [pbr::OriginalName("ENDPOINTER_EVENT_UNSPECIFIED")] EndpointerEventUnspecified = 0,
        /// <summary>
        /// Speech has been detected in the audio stream.
        /// </summary>
        [pbr::OriginalName("START_OF_SPEECH")] StartOfSpeech = 1,
        /// <summary>
        /// Speech has ceased to be detected in the audio stream.
        /// </summary>
        [pbr::OriginalName("END_OF_SPEECH")] EndOfSpeech = 2,
        /// <summary>
        /// The end of the audio stream has been reached. and it is being processed.
        /// </summary>
        [pbr::OriginalName("END_OF_AUDIO")] EndOfAudio = 3,
        /// <summary>
        /// This event is only sent when `single_utterance` is `true`. It indicates
        /// that the server has detected the end of the user's speech utterance and
        /// expects no additional speech. Therefore, the server will not process
        /// additional audio. The client should stop sending additional audio data.
        /// </summary>
        [pbr::OriginalName("END_OF_UTTERANCE")] EndOfUtterance = 4,
      }

    }
    #endregion

  }

  /// <summary>
  /// A speech recognition result corresponding to a portion of the audio that is
  /// currently being processed.
  /// </summary>
  public sealed partial class StreamingRecognitionResult : pb::IMessage<StreamingRecognitionResult> {
    private static readonly pb::MessageParser<StreamingRecognitionResult> _parser = new pb::MessageParser<StreamingRecognitionResult>(() => new StreamingRecognitionResult());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<StreamingRecognitionResult> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[10]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionResult() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionResult(StreamingRecognitionResult other) : this() {
      alternatives_ = other.alternatives_.Clone();
      isFinal_ = other.isFinal_;
      stability_ = other.stability_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public StreamingRecognitionResult Clone() {
      return new StreamingRecognitionResult(this);
    }

    /// <summary>Field number for the "alternatives" field.</summary>
    public const int AlternativesFieldNumber = 1;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative> _repeated_alternatives_codec
        = pb::FieldCodec.ForMessage(10, global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative> alternatives_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative>();
    /// <summary>
    /// [Output-only] May contain one or more recognition hypotheses (up to the
    /// maximum specified in `max_alternatives`).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative> Alternatives {
      get { return alternatives_; }
    }

    /// <summary>Field number for the "is_final" field.</summary>
    public const int IsFinalFieldNumber = 2;
    private bool isFinal_;
    /// <summary>
    /// [Output-only] If `false`, this `SpeechRecognitionResult` represents an
    /// interim result that may change. If `true`, this is the final time the
    /// speech service will return this particular `SpeechRecognitionResult`,
    /// the recognizer will not return any further hypotheses for this portion of
    /// the transcript and corresponding audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool IsFinal {
      get { return isFinal_; }
      set {
        isFinal_ = value;
      }
    }

    /// <summary>Field number for the "stability" field.</summary>
    public const int StabilityFieldNumber = 3;
    private float stability_;
    /// <summary>
    /// [Output-only] An estimate of the probability that the recognizer will not
    /// change its guess about this interim result. Values range from 0.0
    /// (completely unstable) to 1.0 (completely stable). Note that this is not the
    /// same as `confidence`, which estimates the probability that a recognition
    /// result is correct.
    /// This field is only provided for interim results (`is_final=false`).
    /// The default of 0.0 is a sentinel value indicating stability was not set.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public float Stability {
      get { return stability_; }
      set {
        stability_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as StreamingRecognitionResult);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(StreamingRecognitionResult other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!alternatives_.Equals(other.alternatives_)) return false;
      if (IsFinal != other.IsFinal) return false;
      if (Stability != other.Stability) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= alternatives_.GetHashCode();
      if (IsFinal != false) hash ^= IsFinal.GetHashCode();
      if (Stability != 0F) hash ^= Stability.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      alternatives_.WriteTo(output, _repeated_alternatives_codec);
      if (IsFinal != false) {
        output.WriteRawTag(16);
        output.WriteBool(IsFinal);
      }
      if (Stability != 0F) {
        output.WriteRawTag(29);
        output.WriteFloat(Stability);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += alternatives_.CalculateSize(_repeated_alternatives_codec);
      if (IsFinal != false) {
        size += 1 + 1;
      }
      if (Stability != 0F) {
        size += 1 + 4;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(StreamingRecognitionResult other) {
      if (other == null) {
        return;
      }
      alternatives_.Add(other.alternatives_);
      if (other.IsFinal != false) {
        IsFinal = other.IsFinal;
      }
      if (other.Stability != 0F) {
        Stability = other.Stability;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            alternatives_.AddEntriesFrom(input, _repeated_alternatives_codec);
            break;
          }
          case 16: {
            IsFinal = input.ReadBool();
            break;
          }
          case 29: {
            Stability = input.ReadFloat();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// A speech recognition result corresponding to a portion of the audio.
  /// </summary>
  public sealed partial class SpeechRecognitionResult : pb::IMessage<SpeechRecognitionResult> {
    private static readonly pb::MessageParser<SpeechRecognitionResult> _parser = new pb::MessageParser<SpeechRecognitionResult>(() => new SpeechRecognitionResult());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechRecognitionResult> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[11]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionResult() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionResult(SpeechRecognitionResult other) : this() {
      alternatives_ = other.alternatives_.Clone();
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionResult Clone() {
      return new SpeechRecognitionResult(this);
    }

    /// <summary>Field number for the "alternatives" field.</summary>
    public const int AlternativesFieldNumber = 1;
    private static readonly pb::FieldCodec<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative> _repeated_alternatives_codec
        = pb::FieldCodec.ForMessage(10, global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative.Parser);
    private readonly pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative> alternatives_ = new pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative>();
    /// <summary>
    /// [Output-only] May contain one or more recognition hypotheses (up to the
    /// maximum specified in `max_alternatives`).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Google.Cloud.Speech.V1Beta1.SpeechRecognitionAlternative> Alternatives {
      get { return alternatives_; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechRecognitionResult);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechRecognitionResult other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!alternatives_.Equals(other.alternatives_)) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= alternatives_.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      alternatives_.WriteTo(output, _repeated_alternatives_codec);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += alternatives_.CalculateSize(_repeated_alternatives_codec);
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechRecognitionResult other) {
      if (other == null) {
        return;
      }
      alternatives_.Add(other.alternatives_);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            alternatives_.AddEntriesFrom(input, _repeated_alternatives_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Alternative hypotheses (a.k.a. n-best list).
  /// </summary>
  public sealed partial class SpeechRecognitionAlternative : pb::IMessage<SpeechRecognitionAlternative> {
    private static readonly pb::MessageParser<SpeechRecognitionAlternative> _parser = new pb::MessageParser<SpeechRecognitionAlternative>(() => new SpeechRecognitionAlternative());
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SpeechRecognitionAlternative> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Speech.V1Beta1.CloudSpeechReflection.Descriptor.MessageTypes[12]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionAlternative() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionAlternative(SpeechRecognitionAlternative other) : this() {
      transcript_ = other.transcript_;
      confidence_ = other.confidence_;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SpeechRecognitionAlternative Clone() {
      return new SpeechRecognitionAlternative(this);
    }

    /// <summary>Field number for the "transcript" field.</summary>
    public const int TranscriptFieldNumber = 1;
    private string transcript_ = "";
    /// <summary>
    /// [Output-only] Transcript text representing the words that the user spoke.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Transcript {
      get { return transcript_; }
      set {
        transcript_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "confidence" field.</summary>
    public const int ConfidenceFieldNumber = 2;
    private float confidence_;
    /// <summary>
    /// [Output-only] The confidence estimate between 0.0 and 1.0. A higher number
    /// means the system is more confident that the recognition is correct.
    /// This field is typically provided only for the top hypothesis, and only for
    /// `is_final=true` results.
    /// The default of 0.0 is a sentinel value indicating confidence was not set.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public float Confidence {
      get { return confidence_; }
      set {
        confidence_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SpeechRecognitionAlternative);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SpeechRecognitionAlternative other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Transcript != other.Transcript) return false;
      if (Confidence != other.Confidence) return false;
      return true;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Transcript.Length != 0) hash ^= Transcript.GetHashCode();
      if (Confidence != 0F) hash ^= Confidence.GetHashCode();
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (Transcript.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Transcript);
      }
      if (Confidence != 0F) {
        output.WriteRawTag(21);
        output.WriteFloat(Confidence);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Transcript.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Transcript);
      }
      if (Confidence != 0F) {
        size += 1 + 4;
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SpeechRecognitionAlternative other) {
      if (other == null) {
        return;
      }
      if (other.Transcript.Length != 0) {
        Transcript = other.Transcript;
      }
      if (other.Confidence != 0F) {
        Confidence = other.Confidence;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            input.SkipLastField();
            break;
          case 10: {
            Transcript = input.ReadString();
            break;
          }
          case 21: {
            Confidence = input.ReadFloat();
            break;
          }
        }
      }
    }

  }

  #endregion

}

#endregion Designer generated code
